# =============================================================================
# FIX: Disable Streamlit file watcher
# =============================================================================
import os
os.environ["STREAMLIT_SERVER_FILE_WATCHER_TYPE"] = "none"

# =============================================================================
# IMPORTS
# =============================================================================
import streamlit as st
import torch
import pickle
import gdown
import torch.nn.functional as F

from transformers import (
    BertTokenizerFast,
    BertConfig,
    BertForSequenceClassification
)

from safetensors.torch import load_file

# =============================================================================
# PAGE CONFIG
# =============================================================================
st.set_page_config(
    page_title="AI Arabic Emotion Analyzer",
    page_icon="ü§ñ",
    layout="centered"
)

# =============================================================================
# PATHS
# =============================================================================
BASE_DIR = "Module1_Text_to_Emotion/models_v2"
MODEL_PATH = os.path.join(BASE_DIR, "model.safetensors")
LABEL_ENCODER_PATH = os.path.join(BASE_DIR, "label_encoder.pkl")
DRIVE_FILE_ID = "12TtvlA3365gKRV0jCtKhCeN9oSk8fK1v"

# =============================================================================
# LOAD MODEL
# =============================================================================
@st.cache_resource
def load_prediction_model():

    if not os.path.exists(MODEL_PATH):
        with st.spinner("Downloading model weights (‚âà500MB)..."):
            os.makedirs(BASE_DIR, exist_ok=True)
            gdown.download(id=DRIVE_FILE_ID, output=MODEL_PATH, quiet=False)

    try:
        tokenizer = BertTokenizerFast.from_pretrained(BASE_DIR)

        config = BertConfig.from_pretrained(BASE_DIR)

        model = BertForSequenceClassification(config)
        state_dict = load_file(MODEL_PATH)
        model.load_state_dict(state_dict)
        model.eval()

        with open(LABEL_ENCODER_PATH, "rb") as f:
            label_encoder = pickle.load(f)

        return tokenizer, model, label_encoder

    except Exception as e:
        st.error(f"‚ùå Critical error loading model: {e}")
        return None, None, None


tokenizer, model, label_encoder = load_prediction_model()

# =============================================================================
# PREDICTION
# =============================================================================
def predict_emotion(text):

    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=128
    )

    with torch.no_grad():
        outputs = model(**inputs)
        probs = F.softmax(outputs.logits, dim=1)[0].cpu().numpy()

    idx = probs.argmax()
    return (
        label_encoder.inverse_transform([idx])[0],
        probs[idx],
        probs
    )

# =============================================================================
# UI
# =============================================================================
st.title("ü§ñ ŸÖÿ≠ŸÑŸÑ ÿßŸÑŸÖÿ¥ÿßÿπÿ± ÿßŸÑÿπÿ±ÿ®Ÿä ÿßŸÑÿ∞ŸÉŸä")

text_input = st.text_area("ÿ£ÿØÿÆŸÑ ÿßŸÑŸÜÿµ:")

if st.button("ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÖÿ¥ÿßÿπÿ± üîç"):
    if not text_input.strip():
        st.warning("ÿßŸÉÿ™ÿ® ŸÜÿµ ÿßŸÑÿ£ŸàŸÑ")
    else:
        emotion, conf, probs = predict_emotion(text_input)
        st.success(f"ÿßŸÑŸÖÿ¥ÿßÿπÿ± ÿßŸÑŸÖÿ™ŸàŸÇÿπÿ©: {emotion} ({conf:.1%})")
